{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The objective of this example is to show how we have implemented the backpropagation algorithm to train a neural\n",
    "network. The example is based on [this](https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c)\n",
    "article."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "from dlfs.activation_functions import Sigmoid, ReLU, Softmax\n",
    "from dlfs.losses import CategoricalCrossentropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The neural network\n",
    "\n",
    "In order to make things simple to compute manually, we have used a small neural network with two input and two\n",
    "output neurons. The network is trained by a single input and a single output (with a batch size of 3).\n",
    "\n",
    "![](images/neural_network.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# the input showed in the web site corresponds to the first sample in the batch. The rest of the samples have\n",
    "# been generated \"randomly\".\n",
    "\n",
    "inp = np.array([[0.1, 0.2, 0.7],\n",
    "                [0.2, 0.3, 0.5],\n",
    "                [0.3, 0.4, 0.6]])\n",
    "\n",
    "output = np.array([[1., 0., 0.],\n",
    "                   [0., 1., 0.],\n",
    "                   [0., 0., 1.]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "weights_ij = np.array([[0.1, 0.2, 0.3],\n",
    "                       [0.3, 0.2, 0.7],\n",
    "                       [0.4, 0.3, 0.9]])\n",
    "\n",
    "bias_j = np.array([1., 1., 1.])\n",
    "\n",
    "weights_jk = np.array([[0.2, 0.3, 0.5],\n",
    "                       [0.3, 0.5, 0.7],\n",
    "                       [0.6, 0.4, 0.8]])\n",
    "\n",
    "bias_k = np.array([1., 1., 1.])\n",
    "\n",
    "weights_kl = np.array([[0.1, 0.4, 0.8],\n",
    "                       [0.3, 0.7, 0.2],\n",
    "                       [0.5, 0.2, 0.9]])\n",
    "\n",
    "bias_l = np.array([1., 1., 1.])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The forward pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Layer 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.35, 1.27, 1.8 ],\n       [1.31, 1.25, 1.72],\n       [1.39, 1.32, 1.91]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_in = inp @ weights_ij + bias_j\n",
    "h1_in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each row of the matrix `h1_in` corresponds to a sample in the batch. The matrix `h1_in` is the input to the first\n",
    "layer. Now we have to apply the activation function to each element of the matrix."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.35, 1.27, 1.8 ],\n       [1.31, 1.25, 1.72],\n       [1.39, 1.32, 1.91]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = ReLU()\n",
    "h1_out = relu(h1_in)\n",
    "h1_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Layer 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.731, 2.76 , 4.004],\n       [2.669, 2.706, 3.906],\n       [2.82 , 2.841, 4.147]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2_in = h1_out @ weights_jk + bias_k\n",
    "h2_in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sigmoid = Sigmoid()\n",
    "h2_out = sigmoid(h2_in)\n",
    "h2_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.93883129, 0.94047563, 0.9820843 ],\n       [0.93517243, 0.93737976, 0.98027604],\n       [0.94374707, 0.94485159, 0.98443434]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Layer 3 (output layer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.86706797, 2.23028232, 2.82303603],\n       [1.86486919, 2.22629002, 2.81786233],\n       [1.87004735, 2.23578181, 2.82995888]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_in = h2_out @ weights_kl + bias_l\n",
    "o_in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.19844689, 0.28535553, 0.51619758],\n       [0.19885349, 0.28542781, 0.5157187 ],\n       [0.19790076, 0.28528827, 0.51681098]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = Softmax()\n",
    "o_out = softmax(o_in)\n",
    "o_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computing the loss (cross-entropy loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Actual Output should be `[1.0, 0.0, 0.0]` but we got `[0.19857651 0.28559493 0.51582856]` (note that we are only\n",
    "focusing on the first sample)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "1.6172337500003393"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = CategoricalCrossentropy()\n",
    "loss = cross_entropy(output[0], o_out[0])\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BackPropagating the error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (Hidden Layer2 â€” Output Layer) Weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "d_loss_d_o_out = cross_entropy.gradient(output, o_out)\n",
    "d_loss_d_o_out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-5.03913152,  1.39929719,  2.06695946],\n       [ 1.24821114, -3.50351285,  2.06491558],\n       [ 1.24672852,  1.3991655 , -1.93494342]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00054148, 0.22402643, 0.22420076],\n       [0.21222988, 0.00263291, 0.21324901],\n       [0.24781641, 0.24922099, 0.01846397]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_o_out_d_o_in = softmax.gradient(d_loss_d_o_out)\n",
    "d_o_out_d_o_in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}